{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBFq+gVlVTu8wwRP2zh0FG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandarrios/tcc_covid_recuperacao/blob/main/TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To Do:\n",
        " \n",
        " - Gráfico de análise temporal da evolução dos casos;\n",
        " - ~Rodar código que acrescenta uma coluna de id para ordenar o gráfico;~\n",
        " - Gráfico com contagem de casos por município(?)"
      ],
      "metadata": {
        "id": "FRp8kwFYpXas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando os dados"
      ],
      "metadata": {
        "id": "BwnvLXGHr-mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados até o dia 17/09/22"
      ],
      "metadata": {
        "id": "QnNl9chHq5Fx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW9jUQP1Fhki"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pandas_profiling.profile_report import ProfileReport\n",
        "\n",
        "\n",
        "def plot_chart(desired_variable, df, column, title):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.countplot(y=desired_variable,\n",
        "                  data=df,\n",
        "                  palette='rocket',\n",
        "                  order=column.value_counts().index).set_title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def fixing_data_type(column, first_symbol, second_symbol):\n",
        "    try:\n",
        "        column = column.apply(lambda x : str(x).replace(first_symbol, second_symbol))\n",
        "        column = pd.to_datetime(column, format='%Y%m%d')\n",
        "    except ValueError:\n",
        "        column = column.apply(lambda x : str(x).replace(first_symbol, second_symbol))\n",
        "        column = pd.to_datetime(column, dayfirst=True)\n",
        "    return column"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "covid_sistema_um = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/XLSX_Sistemas_1.txt', sep='\\t')\n",
        "covid_sistema_dois = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/XLSX_Sistemas_2.txt', sep='\\t')\n",
        "covid_sistema_tres = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/XLSX_Sistemas_3.txt', sep='\\t')\n",
        "covid_sistema_quatro = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/xlsx_sistemas.txt', sep='\\t')\n",
        "\n",
        "covid_sistema_um['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_um['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_dois['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_dois['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_tres['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_tres['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_quatro['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_quatro['DATA_NOTIFICACAO'], '/', '-')\n",
        "\n",
        "covid_df = pd.concat([covid_sistema_um, covid_sistema_dois, covid_sistema_tres,\n",
        "                      covid_sistema_quatro])\n",
        "\n",
        "report = ProfileReport(covid_df, title='Primeira investigação do dataset')\n",
        "report.to_file('TCC_COVID_REPORT_1.html')"
      ],
      "metadata": {
        "id": "JQkkUQBGre20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise Exploratória"
      ],
      "metadata": {
        "id": "tMoa0zTmr2W4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Eliminando colunas que não fazem sentido para o nosso problema e nem faz sentido para conhecermos o dataset"
      ],
      "metadata": {
        "id": "lviAmGvIrig6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df.drop(columns=['ID', 'CODIGO', 'DATA_EVOLUCAO', 'MICRO', 'MACRO', \n",
        "                       'ETNIA', 'MUNICIPIO_RESIDENCIA', 'DATA_1_SINTOMA', 'URS', \n",
        "                       'DATA_ATUALIZACAO', 'CLASSIFICACAO_CASO'], inplace=True)"
      ],
      "metadata": {
        "id": "8g_BGhVUrf75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Como vimos no profile report, temos valores para idade que não fazem sentido, vamos investigar melhor"
      ],
      "metadata": {
        "id": "fGXfCaPXsxXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Alguém de quase 400 anos não faz sentido, pode ter ocorrido algum erro de digitação. \n",
        " \n",
        " Vamos analisar melhor os outliers"
      ],
      "metadata": {
        "id": "epj3zNzHs3TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df['IDADE'].min()\n",
        "covid_df['IDADE'].max()"
      ],
      "metadata": {
        "id": "nk1nuSsvszIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(covid_df['IDADE'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PHs8Rwdp6maR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tem 1127 outliers e 1825 valores nulos, no primeiro momento pensei em só pegar os dois primeiros números e considerar o terceiro como erro de digitação e, mas o preenchimento da faixa etária deve ter ocorrido de forma automática de acordo com o input manual da idade. Decidi então estabelecer um valor máximo de idade de 100 anos, e filtrar todos os valores que fogem disso."
      ],
      "metadata": {
        "id": "FrJKAy2XtD-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df = covid_df.loc[covid_df['IDADE'] <= 100]"
      ],
      "metadata": {
        "id": "L4VunXQ24ywY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(covid_df['IDADE'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AiaqzT096tvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contagem por faixa etária "
      ],
      "metadata": {
        "id": "1P1XNNl7zsI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df['FAIXA_ETARIA'].value_counts()\n",
        "plot_chart('FAIXA_ETARIA', covid_df, covid_df['FAIXA_ETARIA'],\n",
        "           'Faixa etária dos casos de covid')"
      ],
      "metadata": {
        "id": "mzRWExqatAXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver, as pessoas mais afetadas foram as pessoas de 30 a 39 anos"
      ],
      "metadata": {
        "id": "Z2ETLAMa6yT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Qual o local que mais publicou informação sobre a covid em MG?"
      ],
      "metadata": {
        "id": "cqY-du0O7ot5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df['ORIGEM_DA_INFORMACAO'].value_counts()\n",
        "plot_chart('ORIGEM_DA_INFORMACAO', covid_df, covid_df['ORIGEM_DA_INFORMACAO'],\n",
        "           'Portal de Publicação')"
      ],
      "metadata": {
        "id": "Wbsr3vlr6xkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O maior portal responsável por divulgar os números da COVID-19 em MG foi o ESUS."
      ],
      "metadata": {
        "id": "Ttup8YwZ7wU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quantas pessoas apresentaram comorbidade?"
      ],
      "metadata": {
        "id": "rnjpgUwq7-sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df['COMORBIDADE'].value_counts()\n",
        "plot_chart('COMORBIDADE', covid_df, covid_df['COMORBIDADE'],\n",
        "           'Presença ou não de comorbidade')"
      ],
      "metadata": {
        "id": "aT-hII7j8DOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Qual a raça predominante?"
      ],
      "metadata": {
        "id": "P6VzeSGJ8GuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df['RACA'].value_counts()\n",
        "plot_chart('RACA', covid_df, covid_df['RACA'], 'Raça dos cidadãos')"
      ],
      "metadata": {
        "id": "jhupsRw-8YZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quantas pessoas foram internadas?"
      ],
      "metadata": {
        "id": "r-xKNWlk8d0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df['INTERNACAO'].value_counts()\n",
        "plot_chart('INTERNACAO', covid_df, covid_df['INTERNACAO'], 'Casos de internação')\n"
      ],
      "metadata": {
        "id": "rh_EdKVT8iwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Elas foram para o uti?"
      ],
      "metadata": {
        "id": "7gH4OlZW8vHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df['UTI'].value_counts()\n",
        "plot_chart('UTI', covid_df, covid_df['UTI'], 'Contagem de casos de internação na UTI')"
      ],
      "metadata": {
        "id": "4Gl5lGU78u5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quantas sobreviveram? Quantas morreram?"
      ],
      "metadata": {
        "id": "kNaVOfev83C5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df['EVOLUCAO'].value_counts()\n",
        "plot_chart('EVOLUCAO', covid_df, covid_df['EVOLUCAO'], 'Contagem de evolução dos casos')\n"
      ],
      "metadata": {
        "id": "AhcFmWvP82uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver, temos muito mais casos de pessoas recuperadas, então teremos que fazer o balanceamento delas. O método escolhido irá ser o oversampling de óbitos."
      ],
      "metadata": {
        "id": "-hYk838X9DZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação para o modelo"
      ],
      "metadata": {
        "id": "OumFHWKtFZG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Eliminando colunas que não fazem sentido para o ML"
      ],
      "metadata": {
        "id": "Yk8-yI7GFeEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_df.drop(columns=['DATA_NOTIFICACAO', 'ORIGEM_DA_INFORMACAO'], inplace=True)"
      ],
      "metadata": {
        "id": "FVzvex3tFl3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoding\n"
      ],
      "metadata": {
        "id": "MV-1OXF9VMzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evolucao_dict = {'RECUPERADO': 1, 'EM ACOMPANHAMENTO': 2, 'OBITO': 3}\n",
        "covid_df['EVOLUCAO_ORDINAL'] = covid_df.EVOLUCAO.map(evolucao_dict)\n",
        "\n",
        "faixa_idade_dict = {\n",
        "    '<1ANO' : 1,\n",
        "    '1 A 9 ANOS': 2,\n",
        "    '10 A 19 ANOS': 3,\n",
        "    '20 A 29 ANOS': 4,\n",
        "    '30 A 39 ANOS': 5,\n",
        "    '40 A 49 ANOS': 6,\n",
        "    '50 A 59 ANOS': 7,\n",
        "    '60 A 69 ANOS': 8,\n",
        "    '70 A 79 ANOS': 9,\n",
        "    '80 A 89 ANOS': 10,\n",
        "    '90 OU MAIS': 11\n",
        "}\n",
        "covid_df['FAIXA_IDADE_ORDINAL'] = covid_df.FAIXA_ETARIA.map(faixa_idade_dict)"
      ],
      "metadata": {
        "id": "n0PiJuyHVPbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pycharm content"
      ],
      "metadata": {
        "id": "Pgk9sUaO3En-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
        "    confusion_matrix, classification_report\n",
        "from collections import Counter\n",
        "from pandas_profiling.profile_report import ProfileReport\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "def plot_chart(desired_variable, df, column, title):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.countplot(y=desired_variable,\n",
        "                  data=df,\n",
        "                  palette='rocket',\n",
        "                  order=column.value_counts().index).set_title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_box_plot(column):\n",
        "    sns.boxplot(column, palette='rocket')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def fixing_data_type(column, first_symbol, second_symbol):\n",
        "    try:\n",
        "        column = column.apply(lambda x : str(x).replace(first_symbol, second_symbol))\n",
        "        column = pd.to_datetime(column, format='%Y%m%d')\n",
        "    except ValueError:\n",
        "        column = column.apply(lambda x : str(x).replace(first_symbol, second_symbol))\n",
        "        column = pd.to_datetime(column, dayfirst=True)\n",
        "    return column\n",
        "\n",
        "\n",
        "def drop_columns(df, columns):\n",
        "    df.drop(columns=columns, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, target_names,\n",
        "                          normalize=False,\n",
        "                          title='Confusion Matrix') :\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap='rocket')\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None :\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize :\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n",
        "        if normalize :\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else :\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"black\" if cm[i, j] > thresh else \"white\")\n",
        "\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "covid_sistema_um = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/data/XLSX_Sistemas_1.txt', sep='\\t')\n",
        "covid_sistema_dois = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/data/XLSX_Sistemas_2.txt', sep='\\t')\n",
        "covid_sistema_tres = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/data/XLSX_Sistemas_3.txt', sep='\\t')\n",
        "covid_sistema_quatro = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/data/xlsx_sistemas.txt', sep='\\t')\n",
        "\n",
        "covid_sistema_um['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_um['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_dois['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_dois['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_tres['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_tres['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_quatro['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_quatro['DATA_NOTIFICACAO'], '/', '-')\n",
        "\n",
        "covid_df = pd.concat([covid_sistema_um, covid_sistema_dois, covid_sistema_tres,\n",
        "                      covid_sistema_quatro])\n",
        "\n",
        "covid_df.info()\n",
        "\n",
        "# covid_df.reset_index(drop=True, inplace=True)\n",
        "# report = ProfileReport(covid_df, title='Primeira investigação do dataset')\n",
        "# report.to_file('TCC_COVID_REPORT_1.html')\n",
        "\n",
        "covid_df.isnull().sum()\n",
        "\n",
        "drop_columns(covid_df, ['ID', 'CODIGO', 'DATA_EVOLUCAO', 'ETNIA', 'MUNICIPIO_RESIDENCIA',\n",
        "                        'MICRO', 'DATA_1_SINTOMA', 'DATA_ATUALIZACAO',\n",
        "                        'CLASSIFICACAO_CASO'])\n",
        "\n",
        "year = covid_df['DATA_NOTIFICACAO'].dt.year\n",
        "year.value_counts()\n",
        "covid_df = covid_df.loc[covid_df['DATA_NOTIFICACAO'].dt.year != 1957]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.figure(figsize=(8, 8))\n",
        "ax.hist(covid_df['DATA_NOTIFICACAO'], bins=50, color='#301934')\n",
        "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
        "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
        "ax.set_xlabel('Data dos casos', fontsize=9)\n",
        "ax.set_ylabel('Ocorrências', fontsize=9)\n",
        "fig.savefig('Quantidade de casos ao decorrer do tempo.jpeg')\n",
        "plt.show()\n",
        "\n",
        "covid_df = covid_df.loc[covid_df['SEXO'] != 'NAO INFORMADO']\n",
        "\n",
        "# covid_df['IDADE'].min()\n",
        "# covid_df['IDADE'].max()\n",
        "# plot_box_plot(covid_df['IDADE'])\n",
        "\n",
        "covid_df = covid_df.loc[covid_df['IDADE'] <= 100]\n",
        "# plot_box_plot(covid_df['IDADE'])\n",
        "\n",
        "# covid_df['FAIXA_ETARIA'].value_counts()\n",
        "# plot_chart('FAIXA_ETARIA', covid_df, covid_df['FAIXA_ETARIA'],\n",
        "#            'Faixa etária dos casos de covid')\n",
        "\n",
        "# covid_df['ORIGEM_DA_INFORMACAO'].value_counts()\n",
        "# plot_chart('ORIGEM_DA_INFORMACAO', covid_df, covid_df['ORIGEM_DA_INFORMACAO'],\n",
        "#            'Portal de Publicação')\n",
        "\n",
        "# covid_df['COMORBIDADE'].value_counts()\n",
        "# plot_chart('COMORBIDADE', covid_df, covid_df['COMORBIDADE'],\n",
        "#            'Presença ou não de comorbidade')\n",
        "#\n",
        "# covid_df['RACA'].value_counts()\n",
        "# plot_chart('RACA', covid_df, covid_df['RACA'], 'Raça dos cidadãos')\n",
        "\n",
        "# covid_df['INTERNACAO'].value_counts()\n",
        "# plot_chart('INTERNACAO', covid_df, covid_df['INTERNACAO'], 'Casos de internação')\n",
        "#\n",
        "# covid_df['UTI'].value_counts()\n",
        "# plot_chart('UTI', covid_df, covid_df['UTI'], 'Contagem de casos de internação na UTI')\n",
        "#\n",
        "# covid_df['EVOLUCAO'].value_counts()\n",
        "# plot_chart('EVOLUCAO', covid_df, covid_df['EVOLUCAO'], 'Contagem de evolução dos casos')\n",
        "\n",
        "# Preparação dos dados para o modelo\n",
        "drop_columns(covid_df, ['DATA_NOTIFICACAO', 'ORIGEM_DA_INFORMACAO', 'IDADE'])\n",
        "\n",
        "encoded_df = pd.get_dummies(covid_df, columns=['SEXO', 'INTERNACAO', 'UTI', 'RACA', 'MACRO',\n",
        "                                               'COMORBIDADE', 'URS'], drop_first=True,\n",
        "                            dtype='int64')\n",
        "\n",
        "faixa_idade_dict = {\n",
        "    '<1ANO' : 1,\n",
        "    '1 A 9 ANOS': 2,\n",
        "    '10 A 19 ANOS': 3,\n",
        "    '20 A 29 ANOS': 4,\n",
        "    '30 A 39 ANOS': 5,\n",
        "    '40 A 49 ANOS': 6,\n",
        "    '50 A 59 ANOS': 7,\n",
        "    '60 A 69 ANOS': 8,\n",
        "    '70 A 79 ANOS': 9,\n",
        "    '80 A 89 ANOS': 10,\n",
        "    '90 OU MAIS': 11\n",
        "}\n",
        "evolucao_dict = {'RECUPERADO': 1, 'EM ACOMPANHAMENTO': 2, 'OBITO': 3}\n",
        "\n",
        "encoded_df['FAIXA_IDADE_ORDINAL'] = encoded_df.FAIXA_ETARIA.map(faixa_idade_dict)\n",
        "encoded_df['EVOLUCAO_ORDINAL'] = encoded_df.EVOLUCAO.map(evolucao_dict)\n",
        "drop_columns(encoded_df, ['FAIXA_ETARIA', 'EVOLUCAO'])\n",
        "\n",
        "# encoded_df[['FAIXA_IDADE_ORDINAL', 'EVOLUCAO_ORDINAL']] = encoded_df[['FAIXA_IDADE_ORDINAL', 'EVOLUCAO_ORDINAL']] .astype('str')\n",
        "\n",
        "# corr = encoded_df.corr()\n",
        "# plt.figure(figsize=(13, 13))\n",
        "# cmap = sns.diverging_palette(230, 20, as_cmap =True)\n",
        "# sns.heatmap(corr, cmap=cmap, center=0, vmin=-1, vmax=1, annot=True, square=True,\n",
        "#             linewidths=5, cbar_kws={'shrink': 0.5})\n",
        "# # plt.show()\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('Correlation.jpeg')\n",
        "\n",
        "y = encoded_df['EVOLUCAO_ORDINAL']\n",
        "X = drop_columns(encoded_df, ['EVOLUCAO_ORDINAL'])\n",
        "\n",
        "sampling_strategy_under = {1: 624100, 2: 116135, 3: 108466}\n",
        "under = RandomUnderSampler(replacement=True, sampling_strategy=sampling_strategy_under,\n",
        "                           random_state=42)\n",
        "# print('Original dataset shape %s' % Counter(y))\n",
        "X_resampled, y_resampled = under.fit_resample(X, y)\n",
        "# print(f'Resampled dataset shape whith RandonUnderSample: {Counter(y_resampled)}.')\n",
        "\n",
        "sampling_strategy_over = {1: 624100, 2: 620999, 3: 620999}\n",
        "over = RandomOverSampler(sampling_strategy=sampling_strategy_over, random_state=42)\n",
        "X_combined_sampling, y_combined_sampling = over.fit_resample(X_resampled, y_resampled)\n",
        "# print(f'Combined RandomOverSampling with RandonUnderSampling: '\n",
        "#       f'{Counter(y_combined_sampling)}')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined_sampling, y_combined_sampling,\n",
        "                                                    test_size=0.2, random_state=42)\n",
        "\n",
        "# Decision Tree\n",
        "model = DecisionTreeClassifier(criterion='entropy')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_tree = model.predict(X_test)\n",
        "\n",
        "accuracy_score(y_true=y_test, y_pred=y_pred_tree)\n",
        "recall_score(y_true=y_test, y_pred=y_pred_tree, average='micro')\n",
        "\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred_tree)\n",
        "\n",
        "plot_confusion_matrix(cnf_matrix,\n",
        "                      target_names=['Recuperado', 'Em acompanhamento', 'Óbito'])\n",
        "plt.show()\n",
        "plt.savefig('Confusion_matrix.jpeg')\n",
        "\n",
        "# accuracy_score(y_test, y_pred_tree)\n",
        "# precision_score(y_true=y_test, y_pred=y_pred_tree, average='micro')\n",
        "# recall_score(y_true=y_test, y_pred=y_pred_tree, average='micro')\n",
        "report = classification_report(y_true=y_test, y_pred=y_pred_tree)"
      ],
      "metadata": {
        "id": "Qu4zc85_3NO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
        "    confusion_matrix, classification_report\n",
        "from collections import Counter\n",
        "from pandas_profiling.profile_report import ProfileReport\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "def fixing_data_type(column, first_symbol, second_symbol):\n",
        "    try:\n",
        "        column = column.apply(lambda x : str(x).replace(first_symbol, second_symbol))\n",
        "        column = pd.to_datetime(column, format='%Y%m%d')\n",
        "    except ValueError:\n",
        "        column = column.apply(lambda x : str(x).replace(first_symbol, second_symbol))\n",
        "        column = pd.to_datetime(column, dayfirst=True)\n",
        "    return column\n",
        "\n",
        "\n",
        "def drop_columns(df, columns):\n",
        "    df.drop(columns=columns, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def plot_chart(desired_variable, df, column, title, xlabel, ylabel, figsize=(12, 8)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.countplot(y=desired_variable,\n",
        "                  data=df,\n",
        "                  palette='rocket',\n",
        "                  order=column.value_counts().index).set_title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.grid(axis='x', linestyle='--')\n",
        "    plt.minorticks_on()\n",
        "\n",
        "\n",
        "def plot_box_plot(column, title, xlabel):\n",
        "    sns.boxplot(column, palette='rocket').set_title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.grid(axis='x', linestyle='--')\n",
        "    plt.minorticks_on()\n",
        "\n",
        "\n",
        "def plot_time_series(column, xlabel, ylabel):\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    ax.hist(column, bins=50, color='#301934')\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
        "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
        "    ax.set_xlabel(xlabel, fontsize=9)\n",
        "    ax.set_ylabel(ylabel, fontsize=9)\n",
        "\n",
        "\n",
        "def save_fig_show(figname):\n",
        "    plt.savefig(f'{figname}.jpeg')\n",
        "    return plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, target_names,\n",
        "                          normalize=False,\n",
        "                          title='Confusion Matrix') :\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap='rocket')\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None :\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize :\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n",
        "        if normalize :\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else :\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"black\" if cm[i, j] > thresh else \"white\")\n",
        "\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "covid_sistema_um = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/data/XLSX_Sistemas_1.txt', sep='\\t')\n",
        "covid_sistema_dois = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/data/XLSX_Sistemas_2.txt', sep='\\t')\n",
        "covid_sistema_tres = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/data/XLSX_Sistemas_3.txt', sep='\\t')\n",
        "covid_sistema_quatro = pd.read_csv(\n",
        "    'C:/Users/nanda/PycharmProjects/puc_tcc/data/xlsx_sistemas.txt', sep='\\t')\n",
        "\n",
        "covid_sistema_um['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_um['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_dois['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_dois['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_tres['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_tres['DATA_NOTIFICACAO'], '-', '')\n",
        "covid_sistema_quatro['DATA_NOTIFICACAO'] = fixing_data_type(\n",
        "    covid_sistema_quatro['DATA_NOTIFICACAO'], '/', '-')\n",
        "\n",
        "covid_df = pd.concat([covid_sistema_um, covid_sistema_dois, covid_sistema_tres,\n",
        "                      covid_sistema_quatro])\n",
        "\n",
        "print(covid_df.info())\n",
        "\n",
        "covid_df.reset_index(drop=True, inplace=True)\n",
        "report = ProfileReport(covid_df, title='Primeira investigação do dataset')\n",
        "report.to_file('TCC_COVID_REPORT_1.html')\n",
        "\n",
        "# TRATAMENTO DOS DADOS\n",
        "print(covid_df.isnull().sum())\n",
        "\n",
        "drop_columns(covid_df, ['ID', 'CODIGO', 'DATA_EVOLUCAO', 'ETNIA', 'MUNICIPIO_RESIDENCIA',\n",
        "                        'MICRO', 'DATA_1_SINTOMA', 'DATA_ATUALIZACAO',\n",
        "                        'CLASSIFICACAO_CASO'])\n",
        "\n",
        "print(f\"Searching for the outlier: \\n{covid_df['DATA_NOTIFICACAO'].dt.year.value_counts()}\")\n",
        "print(covid_df.loc[covid_df['DATA_NOTIFICACAO'].dt.year == 1957])\n",
        "covid_df = covid_df.loc[covid_df['DATA_NOTIFICACAO'].dt.year != 1957]\n",
        "print(f\"After deleting the outlier:\\n{covid_df['DATA_NOTIFICACAO'].dt.year.value_counts()}\")\n",
        "\n",
        "plot_time_series(covid_df['DATA_NOTIFICACAO'], 'Date', 'Number of cases')\n",
        "save_fig_show('Number of cases over time.')\n",
        "\n",
        "covid_df = covid_df.loc[covid_df['SEXO'] != 'NAO INFORMADO']\n",
        "\n",
        "plot_box_plot(covid_df['IDADE'], 'Age of patients', 'Age')\n",
        "save_fig_show('Age')\n",
        "\n",
        "print(f\"Looking for the outliers: \" \n",
        "      f\"{covid_df.loc[covid_df['IDADE'] > 100, ['IDADE', 'FAIXA_ETARIA']]}\")\n",
        "\n",
        "covid_df = covid_df.loc[covid_df['IDADE'] <= 100]\n",
        "plot_box_plot(covid_df['IDADE'], 'Age of patients', 'Age')\n",
        "save_fig_show('Age_filtered')\n",
        "\n",
        "print(covid_df.duplicated().sum())\n",
        "\n",
        "covid_df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "print(covid_df.duplicated().sum())\n",
        "\n",
        "\n",
        "plot_chart(covid_df['MACRO'], covid_df, covid_df['MACRO'], 'Cases by Macroregion',\n",
        "           'Cases', 'Macroregion', figsize=(16, 8))\n",
        "save_fig_show('Macroregion_cases')\n",
        "\n",
        "plot_chart(covid_df['URS'], covid_df, covid_df['URS'], 'Cases by URS', 'Cases', 'URS',\n",
        "           figsize=(18, 10))\n",
        "save_fig_show('Cases_by_urs')\n",
        "\n",
        "\n",
        "# plot_chart('FAIXA_ETARIA', covid_df, covid_df['FAIXA_ETARIA'],\n",
        "#            'Age Range of COVID-19 cases', 'Case Count', 'Age Range')\n",
        "# plt.figure(figsize=(15, 10))\n",
        "# covid_df['FAIXA_ETARIA'].value_counts().sort_index().plot.bar()\n",
        "# plt.show()\n",
        "# # ANÁLISE EXPLORATÓRIA\n",
        "# # covid_df['FAIXA_ETARIA'].value_counts()\n",
        "# plot_chart('FAIXA_ETARIA', covid_df, covid_df['FAIXA_IDADE_ORDINAL'],\n",
        "#            'Age Range of COVID-19 cases', 'Case Count', 'Age Range')\n",
        "# save_fig_show('Age_range_count')\n",
        "\n",
        "# covid_df['ORIGEM_DA_INFORMACAO'].value_counts()\n",
        "# plot_chart('ORIGEM_DA_INFORMACAO', covid_df, covid_df['ORIGEM_DA_INFORMACAO'],\n",
        "#            'Portal de Publicação')\n",
        "\n",
        "# covid_df['COMORBIDADE'].value_counts()\n",
        "# plot_chart('COMORBIDADE', covid_df, covid_df['COMORBIDADE'],\n",
        "#            'Presença ou não de comorbidade')\n",
        "#\n",
        "# covid_df['RACA'].value_counts()\n",
        "# plot_chart('RACA', covid_df, covid_df['RACA'], 'Raça dos cidadãos')\n",
        "\n",
        "# covid_df['INTERNACAO'].value_counts()\n",
        "# plot_chart('INTERNACAO', covid_df, covid_df['INTERNACAO'], 'Casos de internação')\n",
        "#\n",
        "# covid_df['UTI'].value_counts()\n",
        "# plot_chart('UTI', covid_df, covid_df['UTI'], 'Contagem de casos de internação na UTI')\n",
        "#\n",
        "\n",
        "print(covid_df['EVOLUCAO'].value_counts())\n",
        "plot_chart('EVOLUCAO', covid_df, covid_df['EVOLUCAO'], 'Case evolution count',\n",
        "           'Case count', 'Case evolution', figsize=(17, 8))\n",
        "save_fig_show('Case_evolution_unbalanced')\n",
        "\n",
        "# Preparação dos dados para o modelo\n",
        "drop_columns(covid_df, ['DATA_NOTIFICACAO', 'ORIGEM_DA_INFORMACAO', 'IDADE'])\n",
        "\n",
        "encoded_df = pd.get_dummies(covid_df, columns=['SEXO', 'INTERNACAO', 'UTI', 'RACA', 'MACRO',\n",
        "                                               'COMORBIDADE', 'URS'], drop_first=True,\n",
        "                            dtype='int64')\n",
        "\n",
        "faixa_idade_dict = {\n",
        "    '<1ANO' : 1,\n",
        "    '1 A 9 ANOS': 2,\n",
        "    '10 A 19 ANOS': 3,\n",
        "    '20 A 29 ANOS': 4,\n",
        "    '30 A 39 ANOS': 5,\n",
        "    '40 A 49 ANOS': 6,\n",
        "    '50 A 59 ANOS': 7,\n",
        "    '60 A 69 ANOS': 8,\n",
        "    '70 A 79 ANOS': 9,\n",
        "    '80 A 89 ANOS': 10,\n",
        "    '90 OU MAIS': 11\n",
        "}\n",
        "evolucao_dict = {'RECUPERADO': 1, 'EM ACOMPANHAMENTO': 2, 'OBITO': 3}\n",
        "\n",
        "encoded_df['FAIXA_IDADE_ORDINAL'] = encoded_df.FAIXA_ETARIA.map(faixa_idade_dict)\n",
        "encoded_df['EVOLUCAO_ORDINAL'] = encoded_df.EVOLUCAO.map(evolucao_dict)\n",
        "drop_columns(encoded_df, ['FAIXA_ETARIA', 'EVOLUCAO'])\n",
        "\n",
        "encoded_df.isnull().sum()\n",
        "# corr = encoded_df.corr()\n",
        "# plt.figure(figsize=(13, 13))\n",
        "# cmap = sns.diverging_palette(230, 20, as_cmap =True)\n",
        "# sns.heatmap(corr, cmap=cmap, center=0, vmin=-1, vmax=1, annot=True, square=True,\n",
        "#             linewidths=5, cbar_kws={'shrink': 0.5})\n",
        "# # plt.show()\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('Correlation.jpeg')\n",
        "\n",
        "y = encoded_df['EVOLUCAO_ORDINAL']\n",
        "X = drop_columns(encoded_df, ['EVOLUCAO_ORDINAL'])\n",
        "\n",
        "sampling_strategy_under = {1: 624100, 2: 116135, 3: 108466}\n",
        "under = RandomUnderSampler(replacement=True, sampling_strategy=sampling_strategy_under,\n",
        "                           random_state=42)\n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "X_resampled, y_resampled = under.fit_resample(X, y)\n",
        "print(f'Resampled dataset shape whith RandonUnderSample: {Counter(y_resampled)}.')\n",
        "\n",
        "sampling_strategy_over = {1: 624100, 2: 620999, 3: 620999}\n",
        "over = RandomOverSampler(sampling_strategy=sampling_strategy_over, random_state=42)\n",
        "X_combined_sampling, y_combined_sampling = over.fit_resample(X_resampled, y_resampled)\n",
        "print(f'Combined RandomOverSampling with RandonUnderSampling: '\n",
        "      f'{Counter(y_combined_sampling)}')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined_sampling, y_combined_sampling,\n",
        "                                                    test_size=0.4, random_state=42)\n",
        "print(f'X test: {X_test.shape}. \\nX train: {X_train.shape}. \\ny test: {y_test.shape}.\\n'\n",
        "      f'y train: {y_train.shape}')\n",
        "# Decision Tree\n",
        "model = DecisionTreeClassifier(criterion='entropy')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_tree = model.predict(X_test)\n",
        "\n",
        "accuracy_score(y_true=y_test, y_pred=y_pred_tree)\n",
        "recall_score(y_true=y_test, y_pred=y_pred_tree, average='micro')\n",
        "\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred_tree)\n",
        "\n",
        "plot_confusion_matrix(cnf_matrix,\n",
        "                      target_names=['Recuperado', 'Em acompanhamento', 'Óbito'])\n",
        "plt.show()\n",
        "plt.savefig('Confusion_matrix.jpeg')\n",
        "\n",
        "# accuracy_score(y_test, y_pred_tree)\n",
        "# precision_score(y_true=y_test, y_pred=y_pred_tree, average='micro')\n",
        "# recall_score(y_true=y_test, y_pred=y_pred_tree, average='micro')\n",
        "report = classification_report(y_true=y_test, y_pred=y_pred_tree)"
      ],
      "metadata": {
        "id": "_RYxi_38KAOI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}